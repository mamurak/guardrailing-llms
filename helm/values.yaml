# Default values for guardrailing-llms.

# Namespace will be automatically set by Helm to {{ .Release.Namespace }}

# Main LLM Configuration
mainLLM:
  name: llama-32-3b-instruct
  storageUri: "oci://quay.io/redhat-ai-services/modelcar-catalog:llama-3.2-3b-instruct"

# Detector Models
detectors:
  gibberish:
    storageUri: "oci://quay.io/mmurakam/model-cars:gibberish-text-detector-v0.1.1"
    threshold: 0.35
  promptInjection:
    storageUri: "oci://quay.io/mmurakam/model-cars:deberta-v3-base-prompt-injection-v2-v0.1.0"
    threshold: 0.5
  hateAndProfanity:
    storageUri: "oci://quay.io/mmurakam/model-cars:granite-guardian-hap-38m-v0.1.0"
    threshold: 0.5

# Orchestrator settings
orchestrator:
  replicas: 1

# Workbench configuration
workbench:
  enabled: true
  name: guardrails-workbench
  image: image-registry.openshift-image-registry.svc:5000/redhat-ods-applications/jupyter-minimal-cpu-py312-ubi9:2025.1
  resources:
    requests:
      cpu: "1"
      memory: 4Gi
    limits:
      cpu: "2"
      memory: 8Gi
  storage:
    size: 1Gi
  gitRepo:
    url: https://github.com/rh-ai-quickstart/guardrailing-llms.git
    enabled: true